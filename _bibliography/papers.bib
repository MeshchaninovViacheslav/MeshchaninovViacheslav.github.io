---
---

@string{aps = {American Physical Society,}}

@article{meshchaninov2024diffusion,
  title={Diffusion on language model encodings for protein sequence generation},
  author={Meshchaninov, Viacheslav and Strashnov, Pavel and Shevtsov, Andrey and Nikolaev, Fedor and Ivanisenko, Nikita and Kardymon, Olga and Vetrov, Dmitry},
  journal={arXiv preprint arXiv:2403.03726},
  year={2025},
  selected={true},
  abbr={ICML},
  abstract={Protein sequence design has seen significant advances through discrete diffusion and autoregressive approaches, yet the potential of continuous diffusion remains underexplored. Here, we present DiMA, a latent diffusion framework that operates on protein language model representations. Through systematic exploration of architectural choices and diffusion components, we develop a robust methodology that generalizes across multiple protein encoders ranging from 8M to 3B parameters. We demonstrate that our framework achieves consistently high performance across sequence-only (ESM-2, ESMc), dual-decodable (CHEAP), and multimodal (SaProt) representations using the same architecture and training approach. We extensively evaluate existing methods alongside DiMA using multiple metrics across two protein modalities, covering quality, diversity, novelty, and distribution matching of generated proteins. DiMA consistently produces novel, high-quality and diverse protein sequences and achieves strong results compared to baselines such as autoregressive, discrete diffusion and flow matching language models. The model demonstrates versatile functionality, supporting conditional generation tasks including protein family-generation, motif scaffolding and infilling, and fold-specific sequence design. This work provides a universal continuous diffusion framework for protein sequence generation, offering both architectural insights and practical applicability across various protein design scenarios.},
  pdf={https://arxiv.org/pdf/2403.03726},
}

@article{lyapustin2022towards,
  title={Towards true detail restoration for super-resolution: A benchmark and a quality metric},
  author={Lyapustin, Eugene and Kirillova, Anastasia and Meshchaninov, Viacheslav and Zimin, Evgeney and Karetin, Nikolai and Vatolin, Dmitriy},
  journal={arXiv preprint arXiv:2203.08923},
  year={2022},
  selected={false},
  abbr={arXiv},
  abstract={Super-resolution (SR) has become a widely researched topic in recent years. SR methods can improve overall image and video quality and create new possibilities for further content analysis. But the SR mainstream focuses primarily on increasing the naturalness of the resulting image despite potentially losing context accuracy. Such methods may produce an incorrect digit, character, face, or other structural object even though they otherwise yield good visual quality. Incorrect detail restoration can cause errors when detecting and identifying objects both manually and automatically. To analyze the detail-restoration capabilities of image and video SR models, we developed a benchmark based on our own video dataset, which contains complex patterns that SR models generally fail to correctly restore. We assessed 32 recent SR models using our benchmark and compared their ability to preserve scene context. We also conducted a crowd-sourced comparison of restored details and developed an objective assessment metric that outperforms other quality metrics by correlation with subjective scores for this task. In conclusion, we provide a deep analysis of benchmark results that yields insights for future SR-based work.},
  pdf={https://arxiv.org/pdf/2203.08923},
}

@inproceedings{shabalin2025tencdm,
  title={Tencdm: Understanding the properties of the diffusion model in the space of language model encodings},
  author={Shabalin, Alexander and Meshchaninov, Viacheslav and Chimbulatov, Egor and Lapikov, Vladislav and Kim, Roman and Bartosh, Grigory and Molchanov, Dmitry and Markov, Sergey and Vetrov, Dmitry},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  selected={true},
  volume={39},
  number={23},
  pages={25110--25118},
  year={2025},
  abbr={AAAI},
  abstract={This paper presents the Text Encoding Diffusion Model (TEncDM), a novel approach to diffusion modeling that operates in the space of pre-trained language model encodings. In contrast to traditionally used embeddings, encodings integrate contextual information. In our approach, we also employ a transformer-based decoder, specifically designed to incorporate context in the token prediction process. We conduct a comprehensive examination of the influence of the encoder, decoder, noise scheduler, and self-conditioning on zero-shot generation. Furthermore, we compare TEncDM with previous approaches on three conditional text generation tasks: QQP, XSum, and Wiki-Auto. The results show that TEncDM exhibits superior performance compared to existing non-autoregressive diffusion models.},
  pdf={https://arxiv.org/pdf/2402.19097},
}