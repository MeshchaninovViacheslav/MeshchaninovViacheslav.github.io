<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Generative flows on discrete state-spaces: Enabling multimodal flows with applications to protein co-design | Viacheslav Meshchaninov </title> <meta name="author" content="Viacheslav Meshchaninov"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%9A%80&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://meshchaninovviacheslav.github.io/notes/bio-informatics/protein%20generation/campbell2024generative/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap" rel="stylesheet"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top py-3 py-md-4" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-bold" href="/" style="font-size: 1.125rem; letter-spacing: -0.025em;"> <span class="font-weight-bold">Viacheslav</span> Meshchaninov </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link text-sm font-weight-medium ml-md-4 " href="/">about </a> </li> <li class="nav-item "> <a class="nav-link text-sm font-weight-medium ml-md-4 " href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link text-sm font-weight-medium ml-md-4 text-primary" href="/notes/">notes <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link text-sm font-weight-medium ml-md-4 " href="/cv/">cv </a> </li> <li class="nav-item ml-md-4"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container ml-md-4"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <article class="post"> <header class="post-header"> <h1 class="post-title">Generative flows on discrete state-spaces: Enabling multimodal flows with applications to protein co-design</h1> <div class="post-authors text-muted"></div> <div class="post-venue text-muted font-italic mb-3"> </div> <p class="post-meta">February 7, 2024</p> <div class="buttons mt-3 mb-4"> <a class="btn btn-primary" href="https://arxiv.org/pdf/2402.04997" role="button" target="_blank" rel="noopener noreferrer"> <i class="fa-solid fa-file-pdf"></i> PDF </a> <a class="btn btn-primary" href="https://github.com/jasonkyuyim/multiflow" role="button" target="_blank" rel="noopener noreferrer"> <i class="fa-brands fa-github"></i> Code </a> </div> <div class="post-tags"> <span class="badge badge-secondary">masked diffusion</span> <span class="badge badge-secondary">proteins</span> <span class="badge badge-secondary">cogeneration</span> </div> </header> <div class="post-content mt-4"> <h2 id="summary">Summary</h2> <hr> <h2 id="technical-details">Technical Details</h2> <hr> <h3 id="discrete-flow-matching">Discrete Flow Matching</h3> <p>For each real datapoint $x_1$, we define a <em>very simple</em> two-state interpolation between the mask token $M$ and the clean value $x_1$:</p> \[p_{t|1}^{\text{mask}}(x_t \mid x_1) = t \, \delta\{x_t, x_1\} + (1 - t) \, \delta\{x_t, M\}, \quad t \in [0, 1]\] <p>Because $p_{t \mid 1}$ is analytically available, the unconditional flow is just:</p> \[p_t(x_t) = \mathbb{E}_{x_1 \sim p_{\text{data}}} \left[ p_{t \mid 1}(x_t \mid x_1) \right]\] <h4 id="training-the-denoiser">Training the denoiser</h4> <p>The goal is a network $\hat{p}^{\theta}_{1 \mid t}(x_1 \mid x_t)$ that predicts the clean value.</p> <p>Because $p_{t \mid 1}$ is in closed form, we can generate training pairs $(x_t, x_1, t)$ without simulating the CTMC.</p> <h4 id="loss-cross-entropy">Loss (cross-entropy)</h4> \[\mathcal{L}_{\text{CE}}(\theta) = \mathbb{E}_{\substack{ x_1 \sim p_{\text{data}} \\ t \sim \mathcal{U}(0,1) \\ x_t \sim p_{t|1}(x_t \mid x_1) }} \left[ -\log \hat{p}^{\theta}_{1|t}(x_1 \mid x_t) \right]\] <p><em>Key fact:</em> $\mathcal{L}_{\text{CE}}$ <strong>does not depend on the rate matrix</strong> you will choose for inference, so training and sampling can be treated separately.</p> <h4 id="constructing-a-timedependent-rate-matrix">Constructing a time‑dependent rate matrix</h4> <p>During inference, we simulate a CTMC whose marginal at every time $t$ is $p_{t\mid 1}(x_t \mid x_1)$.<br> One valid choice (there are infinitely many) is the <strong>minimal-jump matrix</strong> $R_t^{\star}$.</p> <h5 id="minimal-jump-matrix-r_tstar">Minimal-jump matrix $R_t^{\star}$</h5> <p>For the masked schedule the formula collapses to:</p> \[R_t^{\star}(x_t, j \mid x_1) = \frac{\delta\{x_t, M\} \, \delta\{j, x_1\}}{1 - t}, \quad 0 \leq t &lt; 1\] <blockquote> <p>Interpretation:</p> <ul> <li>You jump <em>only</em> when you are currently masked.</li> <li>You jump <em>only</em> to the correct clean value $x_1$.</li> <li>The hazard $(1 - t)^{-1}$ grows as $t \to 1$, guaranteeing that the jump occurs before time 1 with probability 1.</li> </ul> </blockquote> <h3 id="multimodal-flows">Multimodal Flows</h3> <p>Following FrameFlow, we refer to the protein structure as the <em>backbone</em> atomic coordinates of each residue.<br> The structure is represented as elements of $\mathrm{SE}(3)$ to capture the rigidity of the local frames along the backbone.</p> <p>A protein of length $D$ residues can then be represented as:</p> \[\left\{ (x^d, r^d, a^d) \right\}_{d=1}^{D}\] <p>where:</p> <ul> <li>$x \in \mathbb{R}^3$ is the translation of the residue’s Carbon-$\alpha$ atom,</li> <li>$r \in \mathrm{SO}(3)$ is a rotation matrix of the residue’s local frame with respect to the global reference frame, and</li> <li>$a \in {1, \ldots, 20} \cup {M}$ is one of 20 amino acids or the mask state $M$.</li> </ul> <p>For brevity, we refer to the residue state as:</p> \[T^d = (x^d, r^d, a^d)\] <p>and let the full protein’s structure and sequence be:</p> \[\mathbf{T} = \{ T^d \}_{d=1}^{D}\] <p>We define the <strong>multimodal conditional flow</strong> as $p_{t\mid 1}(\mathbf{T}_t \mid \mathbf{T}_1)$ to factorize over both dimensions and modality.</p> <p>We impose <strong>independence over both residues and modalities</strong>:</p> \[p_{t\mid 1}(\mathbf{T}_t \mid \mathbf{T}_1) = \prod_{d=1}^{D} p_{t\mid 1}(x_t^d \mid x_1^d) \, p_{t\mid 1}(r_t^d \mid r_1^d) \, p_{t\mid 1}(a_t^d \mid a_1^d)\] <p><em>Continuous schedules</em> (identical to FrameFlow / Yim et al. 2023a):</p> <ul> <li> <p>Translation:</p> \[x_t^d = t x_1^d + (1 - t)x_0^d, \quad x_0^d \sim \mathcal{N}(0, I)\] </li> <li> <p>Rotation: \(r_t^d = \exp_{r_0^d} \left( t \log_{r_0^d}(r_1^d) \right), \quad r_0^d \sim \mathcal{U}_{\mathrm{SO}(3)}\)</p> </li> </ul> <p><em>Discrete mask schedule</em> (our focus):</p> \[p_{t\mid 1}(a_t^d \mid a_1^d) = t \, \delta\{a_t^d, a_1^d\} + (1 - t) \, \delta\{a_t^d, M\}\] <h4 id="trajectory-generator">Trajectory generator</h4> <p>We build a <em>single</em> multimodal process whose marginal at every time matches the factorised $p_{t\mid 1}$.</p> <ul> <li>Continuous modalities. Choose velocity fields that individually produce the conditional marginals:</li> </ul> \[v_x^d(x_t^d \mid x_1^d) = \frac{x_1^d - x_t^d}{1 - t}, \quad v_r^d(r_t^d \mid r_1^d) = \frac{\log_{r_t^d}(r_1^d)}{1 - t}\] <p>With Euler integration (step $\Delta t$):</p> \[x_{t + \Delta t}^d = x_t^d + v_x^d \Delta t, \quad r_{t + \Delta t}^d = \exp_{r_t^d}(\Delta t \, v_r^d)\] <ul> <li>Discrete modality — minimal-jump CTMC</li> </ul> \[R_t^{\star}(a_t^d \rightarrow j \mid a_1^d) = \frac{\delta\{a_t^d, M\} \, \delta\{j, a_1^d\}}{1 - t} \qquad \text{(15)}\] <h4 id="training-objective">Training objective</h4> <p>Sample $t \sim \mathcal{U}(0, 1)$ and corrupt $\mathbf{T}_1$:</p> \[\mathbf{T}_t = \left\{ t x_1^d + (1 - t) x_0^d,\ \exp_{r_0^d}\left[t \log_{r_0^d}(r_1^d)\right],\ \text{Bernoulli}(t, a_1^d, M) \right\}_{d=1}^{D}\] <p>The network predicts:</p> \[\hat{x}_1^d,\ \hat{r}_1^d,\ \hat{\pi}(\cdot \mid \mathbf{T}_t, t)\] <p>Independent losses per modality:</p> \[\mathcal{L}(\theta) = \mathbb{E} \left[ \underbrace{\frac{\|\hat{x}_1^d - x_1^d\|_2^2}{1 - t}}_{\text{trans.}} + \underbrace{\frac{\| \log_{r_t^d}(r_1^d) - \log_{r_t^d}(r^d) \|_2^2}{1 - t}}_{\text{rot.}} - \underbrace{\log \hat{\pi}_{a_1^d}}_{\text{amino acid}} \right]\] <p>To enable flexible sampling options, we can use a noise level for the structure, t, that is independent to the noise level of the sequence, $\tilde{t}$.</p> <p><strong>Architecture</strong><br> The paper uses an IPA backbone from FrameFlow, plus a transformer head for sequence logits; any SE(3)-equivariant encoder-decoder that outputs these three targets suffices.</p> <h4 id="sampling-algorithm-euler--ctmc-thinning">Sampling algorithm (Euler + CTMC-thinning)</h4> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">input </span><span class="pi">:</span> <span class="s">trained network f_θ , step Δt (e.g. 1e-4)</span>
<span class="na">output</span><span class="pi">:</span> <span class="s">protein sample 𝒯 ∼ p_data</span>

<span class="c1"># 0. initialise at pure noise</span>
<span class="s">t ← </span><span class="m">0</span>
<span class="na">for d = 1 … D</span><span class="pi">:</span>
  <span class="s">x^d ← 𝒩(0, I)</span>                <span class="c1"># translation noise</span>
  <span class="s">r^d ← Uniform_SO(3)</span>         <span class="c1"># rotation noise</span>
  <span class="s">a^d ← M</span>                     <span class="c1"># fully masked sequence</span>

<span class="c1"># 1. forward simulation</span>
<span class="na">while t &lt; 1</span><span class="pi">:</span>

  <span class="c1"># 1.1 network predictions</span>
  <span class="pi">{</span><span class="nv">x̂_1^d</span><span class="pi">,</span> <span class="nv">r̂_1^d</span><span class="pi">,</span> <span class="nv">π̂^d</span><span class="pi">}</span> <span class="s">← f_θ({x^d, r^d, a^d}, t)</span>

  <span class="s"># 1.2 continuous Euler step</span>
  <span class="s">x^d ← x^d + (x̂_1^d − x^d)/(1 − t) * Δt</span>
  <span class="s">r^d ← Exp_{r^d}( (log_{r^d}(r̂_1^d))/(1 − t) * Δt )</span>

  <span class="s"># 1.3 sequence CTMC step (per residue)</span>
  <span class="s">if a^d == M</span><span class="err">:</span>
    <span class="s">λ ← 1 / (1 − t)</span>                     <span class="c1"># total rate</span>
    <span class="s">stay_prob ← max(0, 1 − λ * Δt)</span>     <span class="c1"># Poisson thinning</span>
    <span class="s">if Uniform(0,1) &gt; stay_prob</span><span class="err">:</span>       <span class="c1"># jump occurs</span>
      <span class="s">a^d ← Cat(π̂^d)</span>                  <span class="c1"># choose new residue</span>

  <span class="s">t ← t + Δt</span>

<span class="s">return {x^d, r^d, a^d}_{d=1}^D</span>
</code></pre></div></div> <blockquote> <p>Notes</p> <ul> <li>1.3 uses the <strong>minimal-jump rule</strong>. To introduce extra randomness, add an $\eta$-scaled detailed-balance matrix before the thinning step.</li> <li>$\Delta t$ can be made adaptive (e.g., $\Delta t \propto 1 - t$) to cope with the diverging rate near $t = 1$.</li> <li>You may stop at $t = 0.999$ and set any remaining $M$ tokens to $\arg\max \hat{\pi}$.</li> </ul> </blockquote> <h2 id="experiments">Experiments</h2> <h3 id="training">Training</h3> <p>Training data consisted of length 60-384 proteins from the Protein Data Bank (PDB) (Berman et al., 2000) that were curated in Yim et al. (2023b) for a total of 18684 proteins.</p> <h3 id="distillation">Distillation</h3> <p>Our analysis revealed the original PDB sequences achieved worse designability than PMPNN. We sought to improve performance by distilling knowledge from other models.</p> <ol> <li>we first replaced the original sequence of each structure in the training dataset with the lowest scRMSD sequence out of 8 generated by PMPNN conditioned on the structure.</li> <li>we generated synthetic structures of random lengths between 60-384 using an initial Multiflow model and added those that passed PMPNN 8 designability into the training dataset with the lowest scRMSD PMPNN sequence.</li> </ol> <h3 id="metrics">Metrics</h3> <ul> <li> <p>Designability. The generated structure is called designable if scRMSD &lt;2˚ A. Designability is the percentage of designable samples.</p> </li> <li> <p>Diversity. We use FoldSeek to report diversity as the number of unique clusters across designable samples.</p> </li> <li> <p>Novelty. Novelty is the average TM-score of each designable sample to its most similar protein in PDB.</p> </li> </ul> <h3 id="co-design-results">Co-design results</h3> <p><img src="/assets/notes-img/bio-informatics/protein%20sequence%20generation/campbell2024generative/1.png" alt="Co-design results" width="600px"></p> <h3 id="forward-and-inverse-folding">Forward and inverse folding</h3> <p><img src="/assets/notes-img/bio-informatics/protein%20generation/campbell2024generative/2.png" alt="folding" width="600px"></p> <div class="bibtex-toggle"> <a href="#" class="bib-toggle-link">view bibtex</a> </div> <div class="bibtex-content" style="display: none"> <pre><code>@article{campbell2024generative,
  title={Generative flows on discrete state-spaces: Enabling multimodal flows with applications to protein co-design},
  author={Campbell, Andrew and Yim, Jason and Barzilay, Regina and Rainforth, Tom and Jaakkola, Tommi},
  journal={arXiv preprint arXiv:2402.04997},
  year={2024}
}</code></pre> </div> </div> </article> <script>
  document.addEventListener("DOMContentLoaded", function () {
    const toggleLink = document.querySelector(".bib-toggle-link");
    if (toggleLink) {
      toggleLink.addEventListener("click", function (e) {
        e.preventDefault();
        const bibContent = document.querySelector(".bibtex-content");
        if (bibContent.style.display === "none") {
          bibContent.style.display = "block";
          toggleLink.textContent = "hide bibtex";
        } else {
          bibContent.style.display = "none";
          toggleLink.textContent = "view bibtex";
        }
      });
    }
  });
</script> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Viacheslav Meshchaninov. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: July 20, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>