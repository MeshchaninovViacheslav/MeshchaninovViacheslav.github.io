<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Riemannian Score-Based Generative Modelling | Viacheslav Meshchaninov </title> <meta name="author" content="Viacheslav Meshchaninov"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%9A%80&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://meshchaninovviacheslav.github.io/notes/generative%20models/diffusion%20models/bortoli2022riemannian/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap" rel="stylesheet"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top py-3 py-md-4" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-bold" href="/" style="font-size: 1.125rem; letter-spacing: -0.025em;"> <span class="font-weight-bold">Viacheslav</span> Meshchaninov </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link text-sm font-weight-medium ml-md-4 " href="/">about </a> </li> <li class="nav-item "> <a class="nav-link text-sm font-weight-medium ml-md-4 " href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link text-sm font-weight-medium ml-md-4 text-primary" href="/notes/">notes <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link text-sm font-weight-medium ml-md-4 " href="/cv/">cv </a> </li> <li class="nav-item ml-md-4"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container ml-md-4"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <article class="post"> <header class="post-header"> <h1 class="post-title">Riemannian Score-Based Generative Modelling</h1> <div class="post-authors text-muted"></div> <div class="post-venue text-muted font-italic mb-3"> </div> <p class="post-meta">July 2, 2024</p> <div class="buttons mt-3 mb-4"> <a class="btn btn-primary" href="https://arxiv.org/pdf/2202.02763" role="button" target="_blank" rel="noopener noreferrer"> <i class="fa-solid fa-file-pdf"></i> PDF </a> <a class="btn btn-primary" href="https://github.com/oxcsml/riemannian-score-sde" role="button" target="_blank" rel="noopener noreferrer"> <i class="fa-brands fa-github"></i> Code </a> </div> <div class="post-tags"> <span class="badge badge-secondary">Riemannian manifolds</span> </div> </header> <div class="post-content mt-4"> <h2 id="motivation">Motivation</h2> <hr> <p>Score-based generative modelling (SGM) consists of a “noising” stage, whereby a diffusion is used to gradually add Gaussian noise to data, and a generative model, which entails a “denoising” process defined by approximating the time-reversal of the diffusion. Existing SGMs assume that data is supported on a Euclidean space, i.e. a manifold with flat geometry. In many domains such as robotics, geoscience or protein modelling, data is often naturally described by distributions living on Riemannian manifolds and current SGM techniques are not appropriate.</p> <h2 id="methodology">Methodology</h2> <hr> <h3 id="euclidean-score-based-generative-modelling">Euclidean Score-based Generative Modelling</h3> <p>Let’s recall here briefly the key concepts behind SGMs on the Euclidean space $\mathbb{R}^d$.</p> <p><br> Consider a forward noising process \((\mathbf{X}_t)_{t \geq 0}\) defined by the following Stochastic Differential Equation (SDE):</p> <p>\begin{equation} \mathrm{d} \mathbf{X}_t = -\mathbf{X}_t \mathrm{d}t + \sqrt{2} \, \mathrm{d}\mathbf{B}_t, \quad \mathbf{X}_0 \sim p_0, \tag{1} \end{equation}</p> <p>where \((\mathbf{B}_t)_{t \geq 0}\) is a $d$-dimensional Brownian motion and $p_0$ is the data distribution. The available data gives us an empirical approximation of $p_0$.</p> <p><br> The time-reversed process \((\mathbf{Y}_t)_{t \geq 0} = (\mathbf{X}_{T - t})_{t \in [0, T]}\) also satisfies an SDE given by</p> \[\begin{equation} \mathrm{d} \mathbf{Y}_t = \left\{ \mathbf{Y}_t + 2 \nabla \log p_{T - t}(\mathbf{Y}_t) \right\} \mathrm{d}t + \sqrt{2} \, \mathrm{d}\mathbf{B}_t, \quad \mathbf{Y}_0 \sim p_T, \tag{2} \end{equation}\] <p>where $p_t$ denotes the density of \(\mathbf{X}_t\). By construction, the law of \(\mathbf{Y}_{T - t}\) is equal to the law of \(\mathbf{X}_t\) for $t \in [0, T]$ and in particular \(\mathbf{Y}_T \sim p_0\). Hence, if one could sample from \((\mathbf{Y}_t)_{t \in [0, T]}\) then its final distribution would be the data distribution $p_0$. Unfortunately we cannot sample exactly from (2) as $p_T$ and the scores $\left( \nabla \log p_t(x) \right)_{t \in [0, T]}$ are intractable. Hence SGMs rely on a few approximations.</p> <ul> <li>$p_T$ is replaced by the reference distribution $\mathcal{N}(0, \mathbb{I}_d)$.</li> <li> <p>the following denoising score matching identity is exploited to estimate the scores:</p> \[\nabla_{x_t} \log p_t(x_t) = \int_{\mathbb{R}^d} \nabla_{x_t} \log p_{t|0}(x_t|x_0) \, p_{t|0}(x_0|x_t) \, \mathrm{d}x_0,\] <p>where $p_{t|0}(x_t|x_0)$ is the transition density of the process (1) which is available in closed form. It follows directly that $\nabla \log p_t$ is the minimizer of</p> \[\ell_t(s) = \mathbb{E} \left[ \| s(\mathbf{X}_t) - \nabla_{x_t} \log p_{t|0}(\mathbf{X}_t | \mathbf{X}_0) \|^2 \right]\] <p>over functions $s$ where the expectation is over the joint distribution of \(\mathbf{X}_0, \mathbf{X}_t\). This result can be leveraged by considering a neural network \(s_\theta : [0, T] \times \mathbb{R}^d \to \mathbb{R}^d\) trained by minimizing the loss function</p> \[\ell(\theta) = \int_0^T \lambda_t \ell_t(s_\theta(t, \cdot)) \mathrm{d}t\] <p>for some weighting function $\lambda_t &gt; 0$.</p> </li> <li>Finally, an Euler–Maruyama discretization of (2) is performed using a discretization step $\gamma$ such that $T = \gamma N$ for \(N \in \mathbb{N}\):</li> </ul> \[\begin{equation} Y_{n+1} = Y_n + \gamma \{ Y_n + 2s_\theta(T - n\gamma, Y_n) \} + \sqrt{2\gamma} Z_n, \quad Y_0 \sim \mathcal{N}(0, \mathbb{I}_d), \quad Z_n \overset{\text{i.i.d.}}{\sim} \mathcal{N}(0, \mathbb{I}_d). \end{equation}\] <h3 id="riemannian-score-based-generative-modelling">Riemannian Score-based Generative Modelling</h3> <details class="details-frame"> <summary> Riemannian manifold explanation </summary> <p><strong>Simple example</strong></p> <p>Imagine the Earth. From space it is a big 3‑D ball, but if you are an ant walking on the surface you can move only east–west and north–south, two directions. So the surface is a 2‑dimensional world living inside 3‑dimensional space. That is what mathematicians call a 2‑dimensional manifold.</p> <p>Exactly the same idea works for:</p> <ul> <li>Roads or wires running through space → 1‑dimensional manifolds.</li> <li>The sheet of paper you are reading → 2‑dimensional manifold.</li> <li>Hard‑to‑picture shapes that sit inside higher‑dimensional space → still manifolds; you just need more imagination (or equations) to see them.</li> </ul> <p><br> Saying “manifold” only tells us where we can go. It does not yet tell us how long a step is, what the shortest route between two towns is, or how to measure an angle between two roads. To add that information we give every point on the surface its own little “ruler”―a dot‑product for the arrows (vectors) that live in the tangent plane at that point. The rule for measuring must change smoothly as you walk around. Once you add those smoothly varying rulers you have a Riemannian manifold.</p> <p><br> Euclidean space, the n-sphere, hyperbolic space, and smooth surfaces in three-dimensional space, such as ellipsoids and paraboloids, are all examples of Riemannian manifolds.</p> </details> <p>Assume that $\mathcal{M}$ is a complete, orientable connected and boundaryless Riemannian manifold, endowed with a Riemannian metric \(g: T \mathcal{M} \times T \mathcal{M} \longrightarrow \mathbb{R}\).</p> <p>Four components are required to extend SGMs to this setting:</p> <ol> <li>a forward noising process on $\mathcal{M}$ which converges to an easy-to-sample reference distribution,</li> <li>a time-reversal formula on $\mathcal{M}$ which defines a backward generative process</li> <li>a method for approximating samples of SDEs on manifolds,</li> <li>a method to efficiently approximate the drift of the time-reversal process.</li> </ol> <blockquote> <p>Noising processes on manifolds</p> </blockquote> <p>The first necessary component is a suitable generic noising process on manifolds that will converge to a convenient stationary distribution. A simple choice is to use Langevin dynamics described by:</p> <p>\begin{equation} \mathrm{d} \mathbf{X}_t = - \frac{1}{2} \nabla U(\mathbf{X}_t) \mathrm{d}t + \mathrm{d}\mathbf{B}_t \tag{3} \end{equation}</p> <p>Two simple choices for $U(x)$:</p> <ol> <li> <p>\(U(x) = \frac{d^2_{\mathcal{M}}(x, \mu)}{2 \gamma^2}\), where $d_{\mathcal(M)}$ is the geodesic distance and $\mu \in \mathcal(M)$ is an arbitrary mean location. <br> In this case \(\nabla U(\mathbf{X}_t) = -\frac{\exp_{\mathbf{X}_t}^{-1}(\mu)}{\gamma^2}\). This is the potential of the ‘Riemannian normal’ distribution.</p> </li> <li> <p>Alternative is \(U(x) = \frac{d^2_{\mathcal{M}}(x, \mu)}{2 \gamma^2} + \log \mid D \exp_{\mathbf{X}_t}^{-1}(\mu) \mid\)</p> </li> </ol> <h2 id="todo">TODO</h2> <div class="bibtex-toggle"> <a href="#" class="bib-toggle-link">view bibtex</a> </div> <div class="bibtex-content" style="display: none"> <pre><code>@article{bortoli2022riemannian,
  title={Riemannian score-based generative modelling},
  author={Bortoli, Valentin De and Mathieu, Emile and Hutchinson, MJ and Thornton, James and Teh, Yee Whye and Doucet, Arnaud},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  year={2022}
}</code></pre> </div> </div> </article> <script>
  document.addEventListener("DOMContentLoaded", function () {
    const toggleLink = document.querySelector(".bib-toggle-link");
    if (toggleLink) {
      toggleLink.addEventListener("click", function (e) {
        e.preventDefault();
        const bibContent = document.querySelector(".bibtex-content");
        if (bibContent.style.display === "none") {
          bibContent.style.display = "block";
          toggleLink.textContent = "hide bibtex";
        } else {
          bibContent.style.display = "none";
          toggleLink.textContent = "view bibtex";
        }
      });
    }
  });
</script> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Viacheslav Meshchaninov. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: July 20, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>