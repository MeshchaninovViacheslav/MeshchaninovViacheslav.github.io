<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Inference-time scaling for diffusion models beyond scaling denoising steps | Viacheslav Meshchaninov </title> <meta name="author" content="Viacheslav Meshchaninov"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%9A%80&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://meshchaninovviacheslav.github.io/notes/generative%20models/diffusion%20models/ma2025inference/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap" rel="stylesheet"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top py-3 py-md-4" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-bold" href="/" style="font-size: 1.125rem; letter-spacing: -0.025em;"> <span class="font-weight-bold">Viacheslav</span> Meshchaninov </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link text-sm font-weight-medium ml-md-4 " href="/">about </a> </li> <li class="nav-item "> <a class="nav-link text-sm font-weight-medium ml-md-4 " href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link text-sm font-weight-medium ml-md-4 text-primary" href="/notes/">notes <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link text-sm font-weight-medium ml-md-4 " href="/cv/">cv </a> </li> <li class="nav-item ml-md-4"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container ml-md-4"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <article class="post"> <header class="post-header"> <h1 class="post-title">Inference-time scaling for diffusion models beyond scaling denoising steps</h1> <div class="post-authors text-muted"></div> <div class="post-venue text-muted font-italic mb-3"> </div> <p class="post-meta">January 16, 2025</p> <div class="buttons mt-3 mb-4"> <a class="btn btn-primary" href="https://arxiv.org/pdf/2501.09732" role="button" target="_blank" rel="noopener noreferrer"> <i class="fa-solid fa-file-pdf"></i> PDF </a> <a class="btn btn-primary" href="" role="button" target="_blank" rel="noopener noreferrer"> <i class="fa-brands fa-github"></i> Code </a> </div> <div class="post-tags"> <span class="badge badge-secondary">tts</span> <span class="badge badge-secondary">diffusion</span> </div> </header> <div class="post-content mt-4"> <h2 id="methodology">Methodology</h2> <hr> <blockquote> <p>We formulate the challenge as a search problem over the sampling noises; in particular, how do we know which sampling noises are good, and how do we search for such noises?</p> </blockquote> <p>All experiments are conducted on ImageNet for class-conditional generation.</p> <h3 id="how-to-scale-at-inference-time">How to Scale at Inference Time</h3> <p>On a high-level, there are two design axes we propose to consider:</p> <ol> <li> <p><strong>Verifiers</strong> are used to evaluate the goodness of candidates. These typically are some pre-trained models that are capable of providing feedback; concretely, verifiers are functions</p> \[\mathcal{V} : \mathbb{R}^{H \times W \times C} \times \mathbb{R}^d \rightarrow \mathbb{R} \tag{1}\] <p>that takes in the generated samples and optionally the corresponding conditions, and outputs a scalar value as the score for each generated sample.</p> </li> <li> <p><strong>Algorithms</strong> are used to find better candidates based on the verifiers scores. Formally defined, algorithms are functions \(f : \mathcal{V} \times D_\theta \times \left\{ \mathbb{R}^{H \times W \times C} \times \mathbb{R}^d \right\}^N \rightarrow \mathbb{R}^{H \times W \times C} \tag{2}\) that takes a verifier $\mathcal{V}$, a pre-trained Diffusion Model $D_\theta$, and $N$ pairs of generated samples and corresponding conditions, and outputs the best initial noises according to the deterministic mapping between noises and samples. Throughout this search procedure, $f$ typically performs multiple forward passes through $D_\theta$. We refer to these additional forward passes as the search cost, which we measure in terms of NFEs as well.</p> </li> </ol> <h3 id="proof-of-concept">Proof of Concept</h3> <p><img src="/assets/notes-img/generative%20models/diffusion%20models/ma2025inference/21.png" alt="folding" width="800px" class="img-frame-black"></p> <p>As a proof of concept, the authors employ a random search strategy over multiple generated samples for the same condition, utilizing ODE generation and refining the result metric, such as FID and IS, using greedy search.</p> <h3 id="supervised-verifier-for-conditioning">Supervised Verifier for conditioning</h3> <div style="float: right; margin-left: 1.5em; width: 45%;"> <p><img src="/assets/notes-img/generative%20models/diffusion%20models/ma2025inference/22.png" alt="folding" width="400px" class="img-frame-black"></p> </div> <p>While scaling NFEs with search demonstrates impressive performance with the oracle verifiers, the key question is whether its effectiveness can be generalized to supervised verifiers with more accessible pre-trained models designed for various vision tasks.</p> <p>The authors focus on improving conditioning in this section. They utilize two classifiers, CLIP and DINO, selecting samples based on the highest predicted probability.</p> <p><br> This strategy also effectively improves the model performance on IS. Nevertheless, we note that, as these classifiers operate point-wise, they are only partially aligned with the goal of FID score. Specifically, the logits they produce only focus on the quality of a single sample without taking population diversity into consideration, which leads to a significant reduction in sample variance and eventually manifests as mode collapse as the compute increases. We term it as \(\textit{Verifier Hacking}\).</p> <div style="clear: both;"></div> <h3 id="self-supervised-verifiers">Self-Supervised Verifiers</h3> <div style="float: right; margin-left: 1.5em; width: 45%;"> <p><img src="/assets/notes-img/generative%20models/diffusion%20models/ma2025inference/23.png" alt="folding" width="400px" class="img-frame-black"></p> </div> <p>The authors observed that the logit prediction of the classifier is correlated with the similarity between the x-predictions of the diffusion model at different stages of generation ($\sigma = 0.4$ and $\sigma = 0$).</p> <p>This result is encouraging for use cases where conditioning information is not available or hard to obtain.</p> <div style="clear: both;"></div> <h3 id="zero-order-search-zo-n">Zero-Order Search (ZO-n)</h3> <p>Previous explorations have predominantly considered a simple random search setup, which is a one-time best-of-N selection strategy on a randomly chosen fixed set of candidates. To mitigate overfitting risks the author propose Zero-Order Search approach:</p> <ol> <li>We start with a random Gaussian noise $\mathbf{n}$ as pivot.</li> <li>Find $N$ candidates in the pivot’s neighborhood. Formally, the neighborhood is defined as $S_n^\lambda = { \mathbf{y} : d(\mathbf{y}, \mathbf{n}) = \lambda }$, where $d(\cdot, \cdot)$ is some distance metric.</li> <li>Run candidates through an ODE solver to obtain samples and their corresponding verifier scores.</li> <li>Find the best candidates, update it to be the pivot, and repeat steps 1–3.</li> </ol> <p><img src="/assets/notes-img/generative%20models/diffusion%20models/ma2025inference/24.png" alt="folding" width="800px" class="img-frame-black"></p> <h3 id="search-over-paths-paths-n">Search over Paths (Paths-n)</h3> <ol> <li>Sample $N$ initial i.i.d. noises and run the ODE solver until some noise level $\sigma$. The noisy samples $x_\sigma$ serve as the search starting point.</li> <li>Sample $M$ i.i.d. noises for each noisy sample, and simulate the forward noising process from $\sigma$ to $\sigma + \Delta f$ to produce ${ x_{\sigma + \Delta f} }$ with size $M$.</li> <li>Run ODE solver on each $x_{\sigma + \Delta f}$ to noise level $\sigma + \Delta f - \Delta b$, and obtain $x_{\sigma + \Delta f - \Delta b}$. Run verifiers on these samples and keep the top $N$ candidates. Repeat steps 2–3 until the ODE solver reaches $\sigma = 0$.</li> <li>Run the remaining $N$ samples through random search and keep the best one.</li> </ol> <p>Since the verifiers are typically not adapted to noisy input, we perform one additional denoising step in step 3 and use the clean x-prediction to interact with the verifiers.</p> <h2 id="inference-time-scaling-in-text-to-image">Inference-Time Scaling in Text-to-Image</h2> <p><img src="/assets/notes-img/generative%20models/diffusion%20models/ma2025inference/25.png" alt="folding" width="800px" class="img-frame-black"></p> <p>In this setup, the authors employ random search on the DrawBench benchmark using various models (indicated at the top of each graph). They then examine how this impacts validation across all models compared to generation without search (represented by vertical bars).</p> <p><img src="/assets/notes-img/generative%20models/diffusion%20models/ma2025inference/26.png" alt="folding" width="800px" class="img-frame-black"></p> <p>The authors then apply algorithms developed for class-conditional generation tasks. It is evident that the results do not transfer well to more complex tasks.</p> <div class="bibtex-toggle"> <a href="#" class="bib-toggle-link">view bibtex</a> </div> <div class="bibtex-content" style="display: none"> <pre><code>@article{ma2025inference,
  title={Inference-time scaling for diffusion models beyond scaling denoising steps},
  author={Ma, Nanye and Tong, Shangyuan and Jia, Haolin and Hu, Hexiang and Su, Yu-Chuan and Zhang, Mingda and Yang, Xuan and Li, Yandong and Jaakkola, Tommi and Jia, Xuhui and others},
  journal={arXiv preprint arXiv:2501.09732},
  year={2025}
}</code></pre> </div> </div> </article> <script>
  document.addEventListener("DOMContentLoaded", function () {
    const toggleLink = document.querySelector(".bib-toggle-link");
    if (toggleLink) {
      toggleLink.addEventListener("click", function (e) {
        e.preventDefault();
        const bibContent = document.querySelector(".bibtex-content");
        if (bibContent.style.display === "none") {
          bibContent.style.display = "block";
          toggleLink.textContent = "hide bibtex";
        } else {
          bibContent.style.display = "none";
          toggleLink.textContent = "view bibtex";
        }
      });
    }
  });
</script> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Viacheslav Meshchaninov. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: July 20, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>